{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correspondence Selection ###\n",
    "\n",
    "The following process is used to automatically compile a training data set to be used in learning a shadow attenuation model. The output of the previous segmentation has provided us with 'patches' of surface that are likely a simliar material, and are spatially connected to each other - partly in the shade, and partly in the open. From those segments we can select a well distributed subset of pixels in the shade, then identify nearby pixels which we hope are the same material in the open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "lidar_import = np.load('data/lidar_data.npz')\n",
    "intensity = lidar_import['intensity']\n",
    "dem = lidar_import['dem']\n",
    "\n",
    "lidar_segment_import = pickle.load(open('data/lidar_segmentation.p', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection Amounts ####\n",
    "\n",
    "Each 'correspondence' will consist of one pixel in the shade, and at least one pixel in the open. Selecting more than one pixel in the open allows for some flexibility in assessing the learned models later in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(131071)\n",
    "\n",
    "number_of_correspondences = 200\n",
    "number_of_candidate_pairs = 5\n",
    "\n",
    "# building a list of (region_id, pixel_index) pairs to build training data from\n",
    "training_pixels_in_shade = []\n",
    "for i in range(number_of_correspondences):\n",
    "    region_id = rng.integers(1, len(lidar_segment_import)+1)\n",
    "    pixel_index = rng.integers(0, len(lidar_segment_import[region_id]['shade']))\n",
    "    training_pixels_in_shade.append((region_id, pixel_index))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Candidate Pixel Identification ####\n",
    "\n",
    "Once we have a batch of randomly selected shadow pixels, we need to pair them up with pixels in the open. The operations below iterate over each training pixel in the shade and perform the following steps:  \n",
    "* Identify all pixels in the open with the same reigon ID\n",
    "* Build a matrix of [x, y, z, intensity] values for each open pixel\n",
    "* Find the *k* nearest candidate pixels to the current training pixel where *k* = `number_of_candidate_pairs`\n",
    "\n",
    "**Note:** this part of the pipeline is highly customizable. In the below, only lidar attributes are used, and the squared-euclidean distance is applied to determine *nearness*. A number of other features (e.g. from the sepctral data), and other distance metrics could be utilized. In practical experiments the current configuration has provided reasonable training data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# building a collection of the form { shade_pixel: possible_open_pixels[] }\n",
    "training_data = {}\n",
    "\n",
    "for region_id, pixel_index in training_pixels_in_shade:\n",
    "    \n",
    "    training_pixel = lidar_segment_import[region_id]['shade'][pixel_index]\n",
    "    training_data[training_pixel] = []\n",
    "\n",
    "    # matrix of observations in associated 'open' patch adjacent to training pixel\n",
    "    candidate_data = np.array([[pixel[0], pixel[1], dem[pixel], intensity[pixel]] \n",
    "                               for pixel in lidar_segment_import[region_id]['open']])\n",
    "    \n",
    "    # scale feature values to candidate max to mitigate uneven weighting\n",
    "    candidate_max = np.max(candidate_data, axis=0)\n",
    "    training_point = np.array([training_pixel[0], training_pixel[1], dem[training_pixel], intensity[training_pixel]])\n",
    "    training_point = training_point / candidate_max\n",
    "\n",
    "    # compute distances of candidate pixels from training pixel; select specified number of \n",
    "    # nearest pixels for inclusion in training output\n",
    "    candidate_distances = np.sum((candidate_data - training_point) ** 2, axis=1)\n",
    "    ascending_distance_indices = np.argsort(candidate_distances)\n",
    "    \n",
    "    for candidate_index in ascending_distance_indices[:number_of_candidate_pairs]:\n",
    "        training_data[training_pixel].append(lidar_segment_import[region_id]['open'][candidate_index])\n",
    "\n",
    "\n",
    "pickle.dump(training_data, open('data/training_correspondences.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
